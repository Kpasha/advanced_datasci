{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ec126b26-8412-4f58-9d4e-9201097006a1",
    "_uuid": "7c6b63e1bc176362412ef6f54fa51977b4c15e12"
   },
   "source": [
    "Import Libraries and Data:\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#load training file\n",
    "train = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n",
    "print(train.head())\n",
    "print('---------------------')\n",
    "print(train.shape)\n",
    "\n",
    "Distribution of Target Variable:\n",
    "\n",
    "log_errors = train['logerror']\n",
    "upper_lim = np.percentile(log_errors, 99.5)\n",
    "lower_lim = np.percentile(log_errors, 0.5)\n",
    "log_errors = log_errors.clip(lower=lower_lim, upper=upper_lim)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.hist(log_errors, bins=300)\n",
    "plt.title('Distribution of Target Variable (log-error)')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('log-error')\n",
    "plt.show()\n",
    "\n",
    "Log-errors are close to normally distributed around a 0 mean, but with a slightly positive skew. There are also a considerable number of outliers, I will explore whether removing these improves model performance.\n",
    "\n",
    "Proportion of Missing Values in Each Column:\n",
    "\n",
    "#load property features/description file\n",
    "prop = pd.read_csv(\"../input/properties_2016.csv\")\n",
    "print(prop.head())\n",
    "print('---------------------')\n",
    "print(prop.shape)\n",
    "\n",
    "nans = prop.drop('parcelid', axis=1).isnull().sum()\n",
    "nans.sort_values(ascending=True, inplace=True)\n",
    "nans = nans / prop.shape[0]\n",
    "#print(nans)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(range(len(nans.index)), nans.values)\n",
    "plt.xticks(range(len(nans.index)), nans.index.values, rotation=90)\n",
    "plt.show()\n",
    "\n",
    "There are several columns which have a very high proportion of missing values. It may be worth analysing these more closely.\n",
    "\n",
    "Monthly Effects on Target Variable\n",
    "\n",
    "train['transaction_month'] = pd.DatetimeIndex(train['transactiondate']).month\n",
    "train.sort_values('transaction_month', axis=0, ascending=True, inplace=True)\n",
    "print(train.head())\n",
    "\n",
    "ax = sns.stripplot(x=train['transaction_month'], y=train['logerror'])\n",
    "\n",
    "For submission we are required to predict values for October, November and December. The differing distributions of the target variable over these months indicates that it may be useful to create an additional 'transaction_month' feature as shown above. Lets have a closer look at the distribution across only October, November and December.\n",
    "\n",
    "ax1 = sns.stripplot(x=train['transaction_month'][train['transaction_month'] > 9], y=train['logerror'])\n",
    "\n",
    "Proportion of Transactions in Each Month\n",
    "\n",
    "trans = train['transaction_month'].value_counts(normalize=True)\n",
    "trans = pd.DataFrame(trans)\n",
    "trans['month'] = trans.index\n",
    "trans = trans.sort_values('month', ascending=True)\n",
    "trans.set_index('month')\n",
    "trans.rename({'transaction_month' : ''})\n",
    "print(trans)\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(range(len(months)), trans['transaction_month'])\n",
    "plt.title('Proportion of Transactions per Month')\n",
    "plt.ylabel('Proportion')\n",
    "plt.xlabel('Month')\n",
    "plt.xticks(range(len(months)), months, rotation=90)\n",
    "plt.show()\n",
    "\n",
    "This datase contains more transactions occuring in the Spring and Summer months, although it must be noted that some transactions from October, November and December have been removed to form the competition's test set (thanks to nonrandom for pointing this out).\n",
    "\n",
    "Feature Importance\n",
    "\n",
    "#fill NaN values with -1 and encode object columns \n",
    "for x in prop.columns:\n",
    "    prop[x] = prop[x].fillna(-1)\n",
    "\n",
    "#many more parcelids in properties file, merge with training file\n",
    "train = pd.merge(train, prop, on='parcelid', how='left')\n",
    "print(train.head())\n",
    "print('---------------------')\n",
    "print(train.shape)\n",
    "\n",
    "\n",
    "for c in train[['transactiondate', 'hashottuborspa', 'propertycountylandusecode', 'propertyzoningdesc', 'fireplaceflag', 'taxdelinquencyflag']]:\n",
    "    label = LabelEncoder()\n",
    "    label.fit(list(train[c].values))\n",
    "    train[c] = label.transform(list(train[c].values))\n",
    "\n",
    "x_train = train.drop(['parcelid', 'logerror', 'transactiondate'], axis=1)\n",
    "y_train = train['logerror']\n",
    "\n",
    "print(x_train.head())\n",
    "print('------------')\n",
    "print(y_train.head())\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=30, max_features=None)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "rf_importance = rf.feature_importances_\n",
    "\n",
    "\n",
    "importance = pd.DataFrame()\n",
    "importance['features'] = x_train.columns\n",
    "importance['importance'] = rf_importance\n",
    "print(importance.head())\n",
    "importance.sort_values('importance', axis=0, inplace=True, ascending=False)\n",
    "print('------------')\n",
    "print(importance.head())\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4), dpi=100)\n",
    "plt.bar(range(len(importance)), importance['importance'])\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Feature Name')\n",
    "plt.ylabel('Importance')\n",
    "plt.xticks(range(len(importance)), importance['features'], rotation=90)\n",
    "plt.show()\n",
    "\n",
    "Here we see that the greatest importance in predicting the log-error comes from features involving taxes and geographical location of the property. Notably, the 'transaction_month' feature that was engineered earlier was the 12th most important feature. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
